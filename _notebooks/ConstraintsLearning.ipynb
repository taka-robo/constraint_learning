{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b02e2db",
   "metadata": {},
   "source": [
    "$\\newcommand{\\vc}[1]{{\\mathbf{\\boldsymbol{{#1}}}}}$\n",
    "\n",
    "# Constraints Learning\n",
    "\n",
    "Assume you have an optimization problem written in terms of $\\mathbf{\\theta}$:\n",
    "\n",
    "$\\min_{\\mathbf{\\theta}} f(\\mathbf{\\theta})$\n",
    "\n",
    "where $f$ maybe be for instance a polynomial or a rationial function, and $\\theta \\in \\mathbb{R}^N$ may be multidimensional. We assume that you can write the above problem in an quivalent QCQP form by using a \"lifting function\" $\\mathbf{l}(\\theta) \\in \\mathbb{R}^M$ and defining the hihger-dimensional lifted state vector\n",
    "\n",
    "$\\mathbf{x}(\\theta) = \\begin{bmatrix}1 \\\\ \\theta \\\\ z_1 \\\\ \\vdots \\\\ z_M \\end{bmatrix} = \n",
    "\\begin{bmatrix}1 \\\\ \\theta \\\\ \\mathbf{l}(\\theta) \\end{bmatrix} \\in \\mathbb{R}^{1+N+M}$ \n",
    "\n",
    "Now we assume that each of the added constraints can itself be written as a quadratic function: \n",
    "\n",
    "$l_m(\\theta) - z_m = \\mathbf{x}(\\theta)^\\top \\mathbf{A}_m \\mathbf{x}(\\theta) = 0$\n",
    "\n",
    "where $\\mathbf{A}_m$ ($m=1\\ldots M$) are the constraints matrices. \n",
    "Sometimes, there may also exist redundant constraints, meaning some other matrices such that\n",
    "\n",
    "$\\mathbf{x}(\\theta)^\\top \\mathbf{B}_m \\mathbf{x}(\\theta) = 0$. \n",
    "\n",
    "The goal of this not is to, for a given lifting function $\\mathbf{l}(\\theta)$, find the form of the redundant vs. primal constraints. \n",
    "\n",
    "**note that currently we just find all constraints and don't distinguish between primal (moment) constraints and redundant constraints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc93763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import shutil\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True if shutil.which('latex') else False,\n",
    "    \"font.family\": \"DejaVu Sans\",\n",
    "    \"font.size\": 12,\n",
    "})\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{bm}')\n",
    "figsize = 7\n",
    "\n",
    "from IPython.display import display\n",
    "%matplotlib inline \n",
    "#%matplotlib widget\n",
    "#%matplotlib notebook\n",
    "\n",
    "from lifters.plotting_tools import savefig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a142b1",
   "metadata": {},
   "source": [
    "# 1. Lifting functions\n",
    "\n",
    "Currently implemented setups:\n",
    "\n",
    "Poly4Lifter: \n",
    "\n",
    "- univariate quartic polynomial\n",
    "- $\\vc{x}^\\top = [1, t, \\underbrace{t^2}_{z}]$\n",
    "- no redundant constraints\n",
    "\n",
    "Poly6Lifter: \n",
    "\n",
    "- univariate sectic polynomial\n",
    "- $\\vc{x}^\\top = [1, t, \\underbrace{t^2}_{z_1}, \\underbrace{t^3}_{z_2}]$\n",
    "- leads to one redundant constraints\n",
    "\n",
    "RangeOnlyLifter:  \n",
    "\n",
    "- $N$ positions in $d$ dimensions\n",
    "- $\\vc{x}^\\top = [1, \\vc{x}_1, \\vc{x}_2, \\cdots , \n",
    "\\underbrace{||\\vc{x}_1||^2}_{z_1}, \n",
    "\\underbrace{||\\vc{x}_2||^2}_{z_2}, \\cdots]$\n",
    "- $N$ moment constraints, no redundant constraints\n",
    "\n",
    "PoseLandmarkLifter: \n",
    "\n",
    "- $K$ landmarks $\\vc{y}_k$, $N$ poses in $d$ dimensions\n",
    "- $\\vc{x}^\\top = [1, \\vc{x}_1, \\text{vec}(\\vc{C}_1), \\vc{y}_1, \\cdots , \n",
    "\\underbrace{\\vc{C}_1\\vc{y_1}}_{\\vc{z}_1}, \\underbrace{\\vc{C}_2\\vc{y_1}}_{\\vc{z}_2}, \\cdots]$\n",
    "- $KNd + Nd^2$ moment constraints, many redundant constraints\n",
    "\n",
    "\n",
    "Stereo1DLifter: \n",
    "\n",
    "- $K$ landmarks $y_k$, 1 position in 1 dimensions ($\\theta=x$)\n",
    "- $\\vc{x}^\\top = [1, x, \\underbrace{\\frac{1}{x-y_1}}_{z_1}, \\cdots, \\underbrace{\\frac{1}{x-y_K}}_{z_K}]$\n",
    "- $K$ moment constraints, $K(K-1)/2$ redundant constraints\n",
    "\n",
    "Stereo2DLifter: \n",
    "\n",
    "- $K$ landmarks $\\vc{y}_k$, 1 pose in 2 dimensions ($\\vc{\\theta}=(x, y, \\alpha)$, or equivalently transform matrix $\\vc{T}=\\begin{bmatrix} \\vc{c}_1(\\alpha) & \\vc{c}_2(\\alpha) & \\begin{bmatrix} x \\\\ y \\end{bmatrix} \\\\ 0 & 0 & 1 \\end{bmatrix})$\n",
    "\n",
    "- $\\vc{x}^\\top = [1, \\vc{c}_1, \\vc{c}_2, x, y,\n",
    "\\underbrace{\\frac{1}{\\vc{e}_y^\\top\\vc{T}{y}_1}\\vc{T}\\vc{y}_1}_{z_1}, \\cdots, \n",
    "\\underbrace{\\frac{1}{\\vc{e}_y^\\top\\vc{T}{y}_K}\\vc{T}\\vc{y}_K}_{z_K}]\n",
    "$\n",
    "with $\\vc{e}_y$ the second vector of the 3d identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifters.custom_lifters import Poly4Lifter, Poly6Lifter, RangeOnlyLifter, \n",
    "from lifters.landmark_lifter import PoseLandmarkLifter\n",
    "from lifters.stere1d_lifter import Stereo1DLifter\n",
    "from lifters.stereo2d_lifter import Stereo2DLifter\n",
    "\n",
    "# finds one moment constraint:\n",
    "#lifter = RangeOnlyLifter(n_positions=5, d=2)\n",
    "\n",
    "# finds one moment constraint:\n",
    "# lifter = Poly4Lifter()\n",
    "\n",
    "# finds two moment and one redundant constraint:\n",
    "#lifter = Poly6Lifter()\n",
    "\n",
    "# just finds the moment constraint:\n",
    "#lifter = PoseLandmarkLifter(n_landmarks=2, n_poses=1, d=2)\n",
    "\n",
    "# stereo examples\n",
    "#lifter = Stereo1DLifter(n_landmarks=3)\n",
    "\n",
    "# below works!! \n",
    "lifter = Stereo2DLifter(n_landmarks=2, level=3)\n",
    "#lifter = Stereo2DLifter(n_landmarks=2, level=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd9f9fb",
   "metadata": {},
   "source": [
    "# 1. \"learn\" constraints matrices\n",
    "\n",
    "The idea is to learn the nullspace of the matrix composed of many randomly generated feasible and lifted points:  \n",
    "Call $\\vc{x}_{i}$ the $i$-th randomly generated setup, then we know that\n",
    "\n",
    "$\\forall i, m: \\quad \\text{trace}(\\vc{x}_{i}{\\vc{x}_{i}}^\\top\\vc{A}_m) = 0$\n",
    "\n",
    "$\\iff$ \n",
    "\n",
    "$\\forall i, m: \\quad  \\underbrace{\\text{vec}(\\vc{X}_{i})^\\top}_{\\vc{y}_{i}^\\top} \\underbrace{\\text{vec}(\\vc{A}_m)}_{\\vc{a}_m} = 0$\n",
    "\n",
    "$\\iff$ \n",
    "\n",
    "$\\vc{a}_m \\in \\mathcal{N}(\\vc{Y}), \\quad \\vc{Y} = \\begin{bmatrix} \\vc{y}_1^{\\top} \\\\ \\vdots \\\\ \\vc{y}_L^{\\top}\\end{bmatrix}$\n",
    "\n",
    "where $L$ is the number of samples. Note that we can reduce the search to the upper triangular part of $\\vc{A}_m$ since we know that resulting matrix needs to be symmetric, but for simplicity we write everything in terms of the full matrix below. \n",
    "We find an orthonormal basis of the nullspace using SVD or QR decomposition, and then construct $\\vc{A}_m$ by undoing the (half-)vec operation. \n",
    "\n",
    "We call $N_0$ the dimension of the nullspace, or the number of basis vectors found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0281872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = lifter.get_theta()\n",
    "x = lifter.get_x(t)\n",
    "print(lifter.unknowns)\n",
    "print(\"theta\", t.shape)\n",
    "print(\"x\", x.shape)\n",
    "print(t)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c31691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate many random setups and collect in matrix Y\n",
    "Y = lifter.generate_Y(factor=3)\n",
    "print(\"shape of setup matrix Y:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f71bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifters.plotting_tools import plot_singular_values\n",
    "# compute nullspace of Y\n",
    "\n",
    "basis, S = lifter.get_basis(Y, method=\"qr\", eps=1e-2)\n",
    "print(\"nullspace basis:\", basis.shape)\n",
    "\n",
    "plot_singular_values(S, eps)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_known = lifter.get_A_known()\n",
    "for Ai in A_known:\n",
    "    x = lifter.get_x(lifter.get_theta())\n",
    "    assert abs(x.T @ Ai @ x) <= 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb2cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate matrices from found nullspace\n",
    "\n",
    "eps = 1e-5\n",
    "A_list = lifter.generate_matrices(basis)\n",
    "\n",
    "max_error = -np.inf\n",
    "\n",
    "# testing only:\n",
    "# make sure all constraints hold for new setups \n",
    "for seed in range(1000):\n",
    "    np.random.seed(seed)\n",
    "    lifter.generate_random_unknowns()\n",
    "    x = lifter.get_x()\n",
    "    \n",
    "    for i, A in enumerate(A_list):\n",
    "        ci = np.abs(x.T @ A @ x)\n",
    "        max_error = max(max_error, ci)\n",
    "        if seed == 0:\n",
    "            print(f\"error of matrix {i}: {ci:.1e}\")\n",
    "        if ci > eps:\n",
    "            print(f\"!! big error for seed {seed}, matrix {i}: {ci:.1e}\")\n",
    "print(\"max constraint error:\", max_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c5742f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot resulting matrices\n",
    "from lifters.plotting_tools import plot_matrices\n",
    "from math import ceil\n",
    "n = 5\n",
    "chunks = ceil(len(A_list) / n)\n",
    "for k in np.arange(chunks):\n",
    "    fig, ax = plot_matrices(A_list, n_matrices=n, start_idx=k*n)\n",
    "    \n",
    "Q, y = lifter.get_Q()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(3, 3)\n",
    "ax.matshow(Q != 0)\n",
    "ax.set_title(\"Q mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f02038",
   "metadata": {},
   "source": [
    "# 2. Solve dual problem\n",
    "\n",
    "Using the learned matrices, we solve the dual problem\n",
    "\n",
    "$\n",
    "\\begin{align} \n",
    "d_n^* = &\\max_{\\rho, \\vc{\\lambda}} -\\rho \\\\\n",
    "&\\text{s.t. } \\vc{Q} + \\sum_{m=1}^n \\lambda_m \\vc{A}_m + \\rho \\vc{A}_0 \\succeq 0\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "where $n \\leq N_0$ denotes the number of constraints we are adding\n",
    "and compare the obtained cost to the cost of the (hopefully globally optimal) solution obtain by solving the original problem with a simple local solver:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "q^* &= \\min_{\\vc{\\theta}} f(\\vc{\\theta})\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61932f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "solver_options = {\n",
    "    \"CVXOPT\": {\n",
    "        \"verbose\": False,\n",
    "        \"refinement\": 1,\n",
    "        \"kktsolver\":\"qr\", # important so that we can solve with redundant constraints\n",
    "        \"feastol\": 1e-5,\n",
    "    }\n",
    "}\n",
    "def solve_dual(Q, A_list, solver = \"CVXOPT\"):\n",
    "    rho = cp.Variable()\n",
    "    \n",
    "    A_0 = np.zeros(Q.shape)\n",
    "    A_0[0, 0] = 1.0\n",
    "    \n",
    "    H = cp.Parameter(Q.shape)\n",
    "    \n",
    "    H.value = Q\n",
    "    H += A_0 * rho\n",
    "    \n",
    "    cp_variables = {}\n",
    "    for i, Ai in enumerate(A_list):\n",
    "        cp_variables[f\"l{i}\"] = cp.Variable()\n",
    "        H += Ai * cp_variables[f\"l{i}\"]\n",
    "        \n",
    "    constraints = [\n",
    "        H >> 0\n",
    "    ]\n",
    "    \n",
    "    prob = cp.Problem(cp.Maximize(-rho), constraints)\n",
    "    try:\n",
    "        prob.solve(solver=solver, **solver_options[solver])\n",
    "        return -rho.value, H.value, prob.status\n",
    "    except:\n",
    "        return None, None, prob.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c76a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def find_local_minimum(a, y, verbose=False):\n",
    "    local_solutions = []\n",
    "    costs = []\n",
    "    \n",
    "    n_inits = 10\n",
    "    #inits = lifter.get_inits(n_inits) # n_inits x 3\n",
    "    inits = [deepcopy(lifter.unknowns)]\n",
    "    \n",
    "    for x_init in inits:\n",
    "        x_local, msg = lifter.local_solver(a=a, y=y, x_init=x_init, verbose=verbose)\n",
    "        print(msg)\n",
    "        if verbose:\n",
    "            print(msg)\n",
    "        if x_local is not None:\n",
    "            costs.append(lifter.get_cost(a=a, y=y, x=x_local))\n",
    "            local_solutions.append(x_local)\n",
    "    local_solutions = np.array(local_solutions)\n",
    "    \n",
    "    if len(costs):\n",
    "        min_local_ind = np.argmin(costs)\n",
    "        min_local_cost = costs[min_local_ind]\n",
    "        best_local_solution = local_solutions[min_local_ind]\n",
    "        return best_local_solution, min_local_cost\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f545b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from progressbar import ProgressBar\n",
    "from copy import deepcopy\n",
    "\n",
    "data = []\n",
    "seeds = [0, 1, 2]\n",
    "\n",
    "n_shuffles = 5\n",
    "\n",
    "a = lifter.landmarks\n",
    "for j, seed in enumerate(seeds):\n",
    "    \n",
    "    # generate random measurements\n",
    "    np.random.seed(seed)\n",
    "    Q, y = lifter.get_Q(noise=1e-1)\n",
    "    \n",
    "    # find global optimum\n",
    "    xhat, local_cost = find_local_minimum(a=deepcopy(a), y=deepcopy(y), verbose=False)\n",
    "    x_vec = lifter.get_x(xhat)\n",
    "    local_costQ = x_vec.T @ Q @ x_vec\n",
    "    assert abs(local_costQ - local_cost) < 1e-8, (local_costQ-local_cost)\n",
    "    \n",
    "    A_shuffle = deepcopy(A_list)\n",
    "    for shuffle in range(n_shuffles):\n",
    "        print(f\"shuffle {shuffle}\")\n",
    "        np.random.seed(shuffle)\n",
    "        np.random.shuffle(A_shuffle)\n",
    "        p = ProgressBar(max_value=len(A_shuffle))\n",
    "        for i in range(1, len(A_shuffle)):\n",
    "            # solve dual\n",
    "            dual_cost, H, status = solve_dual(Q, A_shuffle[:i])\n",
    "\n",
    "            eigs = np.linalg.eigvalsh(H) if H is not None else None\n",
    "            data.append({\n",
    "                \"n\": i, \n",
    "                \"seed\":j , \n",
    "                \"shuffle\":shuffle,\n",
    "                \"dual cost\":dual_cost, \n",
    "                \"local cost\":local_cost, \n",
    "                \"eigs\":eigs, \n",
    "                \"status\":status\n",
    "            })\n",
    "            p.update(i)\n",
    "    df = pd.DataFrame(data, columns=data[-1].keys())\n",
    "    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a8183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "palette = \"viridis\"\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(data=df, x=\"n\", y=\"dual cost\", style=\"seed\", hue=\"shuffle\", ax=ax, palette=palette)\n",
    "sns.lineplot(data=df[df.shuffle==0], x=\"n\", y=\"local cost\", style=\"seed\", hue=\"shuffle\", ax=ax, palette=palette, legend=False)\n",
    "ax.set_ylabel(\"cost\")\n",
    "ax.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c6e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eigs = 5\n",
    "for seed, df_seed in df.groupby(\"seed\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    cmap = plt.get_cmap(lut=len(df_seed.n.unique()), name=palette)\n",
    "    df_seed = df_seed[df_seed.shuffle==0]\n",
    "    for (n, shuffle), df_n in df_seed.groupby([\"n\", \"shuffle\"]):\n",
    "        assert len(df_n) == 1\n",
    "        row = df_n.iloc[0]\n",
    "        label = f\"n={row.n}\"\n",
    "        if row.eigs is not None:\n",
    "            if n % 10 == 0:\n",
    "                ax.plot(row.eigs[:n_eigs], color=cmap(n), label=label)\n",
    "                label = None\n",
    "    ax.set_title(f\"smallest {n_eigs} eigenvalues of H\")\n",
    "    ax.set_xticks(range(n_eigs))\n",
    "    ax.legend()\n",
    "    ax.set_yscale(\"symlog\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5128278",
   "metadata": {},
   "source": [
    "# 3. larger-scale study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4a3163",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df = pd.read_pickle(\"_results/redundant_test_all.pkl\")\n",
    "df = pd.read_pickle(\"../_results/redundant_test.pkl\") # added extra constraints\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d6724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_label(coeffs):\n",
    "    label = \"\"\n",
    "    for i, c in enumerate(coeffs):\n",
    "        deg = len(coeffs) - i\n",
    "        if deg > 1:\n",
    "            if abs(c) > 1e-10:\n",
    "                label += f\"{c:.1f}$x^{deg}$ + \"\n",
    "        elif deg == 1:\n",
    "            if abs(c) > 1e-10:\n",
    "                label += f\"{c:.1f}$x$ + \"\n",
    "        else:\n",
    "            label += f\"{c:.1f}\"\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf7a18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "for N, df_N in df.groupby(\"n_poses\"):\n",
    "    x = np.r_[df_N.n_landmarks]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x, np.r_[df_N.n_known], label=\"known\", color=\"C0\")\n",
    "    for i, label in enumerate([\"missing\", \"found\"]):\n",
    "        y = np.r_[df_N[\"n_\"+label]]\n",
    "        plt.plot(x, y, label=label, color=f\"C{i+1}\")\n",
    "\n",
    "        coeffs = np.polyfit(x, y, 2)\n",
    "        \n",
    "        #a2_a0, *_ = curve_fit(lambda x, a, b: a*x**2 + b, x, y)\n",
    "        #a2, a0 = a2_a0\n",
    "        #coeffs = [a2, 0, a0]\n",
    "        #print(\"rounding:\", coeffs)\n",
    "        \n",
    "        coeffs = np.round(coeffs, 1)\n",
    "        poly = np.poly1d(coeffs)\n",
    "        label= poly_label(poly) #f\"{coeffs[0]:.1f}$x^2$ + {coeffs[1]:.1f}$x$ + {coeffs[2]:.1f}\"\n",
    "        plt.plot(x, poly(x), label=label, ls=\"\", marker='o', color=f\"C{i+1}\")\n",
    "    plt.plot()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"K\")\n",
    "    plt.title(f\"N={N}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe88082f",
   "metadata": {},
   "source": [
    "# 4. Next steps\n",
    "\n",
    "- Using the $A_m$ that we know, try to complete the basis, so that it stays sparse. \n",
    "- Finish test on landmark-based SLAM problem\n",
    "- Add Lasserre hierarchy option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4071f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
